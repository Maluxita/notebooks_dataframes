{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Repo Checklist Evaluate Computations [V 0.0.1 ]",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWsRirSuQcnq",
        "colab_type": "text"
      },
      "source": [
        "#SECTION 0: Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeaHrSp2xL-D",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Generar Token de Acceso a Carpetas Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vQdu4ZoxkKY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Listar carpetas en PRI_CNIP_ESTRUCTURAS/computos/edo/casillas/*mun*\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "dir_computos=\"/gdrive/My\\ Drive/PRI_CNIP_ESTRUCTURAS/computos/\"\n",
        "dir_mun_pattern_sufix='/'+'*casillas*/' + '*municipio*'\n",
        "\n",
        "def get_list_ls(pattern):\n",
        "  'return list from ls pattern and its len'\n",
        "  list_ls=[]\n",
        "  try: \n",
        "    list_ls = !ls {pattern} | tr '\\n' '\\n'\n",
        "  except:\n",
        "    pass\n",
        "  if 'cannot' in list_ls[0]:\n",
        "    list_ls = []\n",
        "  return list_ls, len(list_ls)\n",
        "\n",
        "\n",
        "def found_links_files(dir_computos,dir_mun_pattern_sufix):\n",
        "  ''' Return links to files with pattern ''' \n",
        "  list_boxes_in_edo=[]\n",
        "  list_data_edo=[]\n",
        "  boxes_in_edo=[]\n",
        "\n",
        "  list_edos, _total = get_list_ls(dir_computos)\n",
        "  \n",
        "  list_edos= filter(lambda x: '0_mexico' not in x,list_edos)\n",
        "  \n",
        "  for edo in list_edos:\n",
        "\n",
        "    sub_dir = dir_computos + edo + dir_mun_pattern_sufix\n",
        "    boxes_in_edo,total_box_files= get_list_ls(pattern=sub_dir)\n",
        "\n",
        "    list_boxes_in_edo.extend(boxes_in_edo)\n",
        "    list_data_edo.append({'edo': edo, \n",
        "                          'found_files':total_box_files })\n",
        "    if not total_box_files:\n",
        "      print(f'El estado {edo} no tiene el patrón casillas municipios ')\n",
        "\n",
        "  df_total_files=pd.DataFrame(list_data_edo)\n",
        "  df_total_files=df_total_files.rename(columns={'edo':'Carpeta Estado', 'found_files': 'Total Found Files'})\n",
        "  df_box=pd.DataFrame(list_boxes_in_edo, columns=['ruta'])\n",
        "\n",
        "  return df_total_files,df_box\n",
        "\n",
        "df_total_files,df_box = found_links_files(dir_computos,dir_mun_pattern_sufix )\n",
        "\n",
        "\n",
        "display(HTML(df_total_files.sort_values(by='Total Found Files', ascending=False).to_html()))\n",
        "display(HTML(df_box.to_html()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNnCNMykrs3p",
        "colab_type": "text"
      },
      "source": [
        "-------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ll9z4yzRscOS"
      },
      "source": [
        "# SECTION 1:  COLUMN CONTINUITY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "r6pnhNBtscOT",
        "colab": {}
      },
      "source": [
        "#@title functions [continuity]\n",
        "import pandas as pd\n",
        "\n",
        "def continuidad_columna(content_books=[], \n",
        "                        sheet_name='Polling_places_corrections',\n",
        "                        column_to_evaluate='local_district_id'\n",
        "                        ):\n",
        "  ''' Evaluá si existe continuidad en columma determinada de una hoja del libro dada, compromando que sea vacía la diferencia simétrica'''\n",
        "  evaluacion_distritos={}\n",
        "\n",
        "  #print ('\\nPara todos los archivos siguientes se evaluará la hoja:',sheet_name,'y la columna:' ,column_to_evaluate)\n",
        "  for book in content_books:\n",
        "\n",
        "    #print('\\nLibro:',book)\n",
        "    try:\n",
        "      df_temp = pd.read_excel(book,sheet_name=sheet_name)\n",
        "      temp_columns=list(df_temp.columns.values)\n",
        "      temp_types=set(df_temp.dtypes.values)\n",
        "      temp_types_by_column=dict(df_temp.dtypes)\n",
        "\n",
        "\n",
        "      \n",
        "    except:\n",
        "      print(f'\\tNo existe la hoja {sheet_name} en el archivo: {book}')\n",
        "      continue\n",
        "\n",
        "    try:\n",
        "      book = book.split('/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/computos/')[1]\n",
        "    except:\n",
        "      book=book\n",
        "\n",
        "    filter_independents=list(filter(lambda x: 'dependiente' in x, temp_columns))\n",
        "\n",
        "    \n",
        "    evaluacion_distritos[book]={}\n",
        "\n",
        "    _df=df_temp.agg({column_to_evaluate:['max','min']})\n",
        "    _unicos = df_temp[column_to_evaluate].unique()\n",
        "\n",
        "    evaluacion_distritos[book]['min'] = _df[column_to_evaluate]['min']\n",
        "    evaluacion_distritos[book]['max'] = _df[column_to_evaluate]['max']\n",
        "    evaluacion_distritos[book]['restaMaxMin'] = _df[column_to_evaluate]['max']-_df[column_to_evaluate]['min']\n",
        "    evaluacion_distritos[book]['shape']= df_temp.shape\n",
        "    evaluacion_distritos[book]['size']= df_temp.size\n",
        "    evaluacion_distritos[book]['columns']=temp_columns\n",
        "    evaluacion_distritos[book]['types']=temp_types\n",
        "    evaluacion_distritos[book]['filter_independents']=filter_independents\n",
        "    evaluacion_distritos[book]['total_independents']=len(filter_independents)\n",
        "\n",
        "    evaluacion_distritos[book]['temp_types_by_column']=temp_types_by_column\n",
        "\n",
        "          \n",
        "\n",
        "    if len(temp_types) == 1:\n",
        "      evaluacion_distritos[book]['temp_types_by_column']='Only One Type'\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "    if not filter_independents:\n",
        "      evaluacion_distritos[book]['filter_independents']='Sin independientes'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if not evaluacion_distritos[book]['restaMaxMin']:\n",
        "      evaluacion_distritos[book]['restaMaxMin']=-1\n",
        "    else:\n",
        "      evaluacion_distritos[book]['restaMaxMin']=len(set(_unicos))\n",
        "\n",
        "\n",
        "\n",
        "    a = set(_unicos)\n",
        "    b = set(np.arange(evaluacion_distritos[book]['min'],evaluacion_distritos[book]['max'] + 1))\n",
        "    c = a^b\n",
        "    evaluacion_distritos[book]['total_diferencia']=len(c)\n",
        "    evaluacion_distritos[book]['diferencia']=\", \".join(map(str,c))\n",
        "\n",
        "  return evaluacion_distritos"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "Sjj34e12scOX",
        "colab": {}
      },
      "source": [
        "#@title Process to evaluate continuity in a column\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "#display(HTML(filter_df_continuity.to_html()))\n",
        "\n",
        "#'''content_books =  \"*.xlsx | tr '\\n' '\\n'\"#@param {type:\"raw\"}\n",
        "#content_books =  !ls {content_books}'''\n",
        "\n",
        "\n",
        "content_books=list(df_box['ruta'])\n",
        "#content_books=['/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/computos/20_oaxaca/oaxaca_casillas/oaxaca_municipios_2013_polling_place.xlsx']\n",
        "\n",
        "\n",
        "#content_books=['san-luis-potosi_2018_polling_place (3) (1).xlsx']\n",
        "column_to_evaluate =  \"municipality_id\"#@param {type:\"string\"}\n",
        "sheet_name=\"Polling_places\"#@param {type:\"string\"}\n",
        "\n",
        "truncate_discontinuous_ids = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "evaluacion_distritos=continuidad_columna(content_books=content_books, \n",
        "                        sheet_name=sheet_name,\n",
        "                        column_to_evaluate=column_to_evaluate\n",
        "                        )\n",
        "\n",
        "df = pd.DataFrame([[key.split('.')[0],value['total_diferencia'],value['diferencia'],\n",
        "                      value['restaMaxMin'],value['min'], value['max'], value['shape'], value['size'], \n",
        "                      value['columns'], value['filter_independents'], value['total_independents'],  value['types'], value['temp_types_by_column']] for key,value in evaluacion_distritos.items()], \n",
        "                  columns=['Libro', 'Total_No_continuos','Lista IDs NO Continuos', 'Total Ids únicos','Mínimo', 'Máximo', 'Filas,Columnas', 'Total Celdas', 'columns', 'filter_independents','total_independents','types', 'temp_types_by_column'])\n",
        "\n",
        "if truncate_discontinuous_ids:\n",
        "  df = pd.DataFrame([[key.split('.')[0],value['total_diferencia'],value['diferencia'][0:50],\n",
        "                      value['restaMaxMin'],value['min'], value['max'], value['shape'], value['size'], \n",
        "                      value['columns'], value['filter_independents'], value['total_independents'],value['types'], value['temp_types_by_column']] for key,value in evaluacion_distritos.items()], \n",
        "                  columns=['Libro', 'Total_No_continuos','Lista IDs NO Continuos', 'Total Ids únicos','Mínimo', 'Máximo', 'Filas,Columnas', 'Total Celdas', 'columns', 'filter_independents','total_independents','types', 'temp_types_by_column'])\n",
        "\n",
        "display(HTML(df.to_html()))\n",
        "#df.to_excel('/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/data_from_notebook/continuity_data.xlsx')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Txm5MBKlkVK",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title save df to file\n",
        "\n",
        "df = pd.DataFrame([[key.split('.')[0],value['total_diferencia'],value['diferencia'],\n",
        "                      value['restaMaxMin'],value['min'], value['max'], value['shape'], value['size'], \n",
        "                      value['columns'], value['filter_independents'], value['total_independents'],  value['types'], value['temp_types_by_column']] for key,value in evaluacion_distritos.items()], \n",
        "                  columns=['Libro', 'Total_No_continuos','Lista IDs NO Continuos', 'Total Ids únicos','Mínimo', 'Máximo', 'Filas,Columnas', 'Total Celdas', 'columns', 'filter_independents','total_independents','types', 'temp_types_by_column'])\n",
        "\n",
        "df.to_excel('/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/data_from_notebook/evaluate_continuity_column_municipality_all_rutes_mi otro nombre.xlsx')\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFLLciPCmvF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "08613795-adc8-428e-df39-d538bbc1b858"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Libro', 'Total_No_continuos', 'Lista IDs NO Continuos',\n",
              "       'Total Ids únicos', 'Mínimo', 'Máximo', 'Filas,Columnas',\n",
              "       'Total Celdas', 'columns', 'filter_independents', 'total_independents',\n",
              "       'types', 'temp_types_by_column'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee5igGLmg4df",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title graph df\n",
        "variable_sort = \"Total Celdas\" #@param {type:\"string\"}\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "fig = px.bar(df.sort_values(by=variable_sort, ascending=False), \n",
        "             y=variable_sort,\n",
        "             x='Libro',\n",
        "             hover_data=['Total Celdas','Filas,Columnas','Total_No_continuos' ,'Total Ids únicos', 'total_independents','Libro'], \n",
        "             color=variable_sort,\n",
        "             labels={'Total Celdas':'Cells'},\n",
        "  \n",
        "             height=400)\n",
        "\n",
        "fig.update_layout(title='View '+ variable_sort,\n",
        "                  xaxis_title='Libro',\n",
        "                  yaxis_title=variable_sort             \n",
        "                  )\n",
        "\n",
        "fig.update_xaxes(tickangle=90, tickfont=dict(family='arial', color='gray', size=6))\n",
        "\n",
        "\n",
        "\n",
        "fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIPIZx-TZ1T4",
        "colab_type": "text"
      },
      "source": [
        "## SUBSECTION FILTER SUMMARY CONTINUIDAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDNdDeBXZhq8",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Ver Total_No_continuos > 0\n",
        "df_continuity=df.copy()\n",
        "filter_df_continuity=df_continuity[ df_continuity['Total_No_continuos']>0]\n",
        "estados=list(map(lambda x: x.split('/')[0], filter_df_continuity['Libro']))\n",
        "filter_df_continuity['Lista IDs NO Continuos']=list(map(lambda x: x[:25], filter_df_continuity['Lista IDs NO Continuos']))\n",
        "filter_df_continuity['columns']=list(map(lambda x: x[4:10], filter_df_continuity['columns']))\n",
        "filter_df_continuity['filter_independents']=list(map(lambda x: x[-2:-1], filter_df_continuity['filter_independents']))\n",
        "\n",
        "\n",
        "filter_df_continuity.insert(0, \"Estado\", estados )\n",
        "display(HTML(filter_df_continuity.to_html()))\n",
        "print(list(filter_df_continuity['Libro']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "qbRtEcDhPv4v",
        "colab": {}
      },
      "source": [
        "#@title Ver Total Ids únicos = -1\n",
        "df_continuity=df.copy()\n",
        "filter_df_continuity=df_continuity[ df_continuity['Total Ids únicos']==-1]\n",
        "estados=list(map(lambda x: x.split('/')[0], filter_df_continuity['Libro']))\n",
        "filter_df_continuity.insert(0, \"Estado\", estados )\n",
        "#filter_df_continuity.to_excel('/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/data_from_notebook/temp_file.xlsx')\n",
        "display(HTML(filter_df_continuity.to_html()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijXCtY81sRJz",
        "colab_type": "text"
      },
      "source": [
        "---------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzt8Do6UOacn",
        "colab_type": "text"
      },
      "source": [
        "#SECTION 2: SABANA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SxU7zlxZIZl",
        "colab_type": "text"
      },
      "source": [
        "* Crea hojas nuevas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxW7Y_6tRKH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mi_lista=['20_oaxaca/oaxaca_casillas/oaxaca_municipios_2013_polling_place',\n",
        "          '7_chiapas/chiapas_casillas/chiapas_municipios_2018_polling_place']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "OgjbYBqHOoL0",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "#state_origin =  1#@param {type:\"integer\"}\n",
        "scan_sheet =  'Polling_places' #@param {type:\"raw\"}\n",
        "sheet=scan_sheet\n",
        "new_sheet =  'Polling_places_sabana_sergs' #@param {type:\"raw\"}\n",
        "column_origin ='section_id'  #@param {type:\"string\"}\n",
        "new_column ='new_municipality_ids'  #@param {type:\"string\"}\n",
        "name_scan_column=  'municipality_id' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "content_books=mi_lista  #@param {type:\"raw\"}\n",
        "origin_computes='/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/computos/'\n",
        "content_books=list(map(lambda x: origin_computes+x+'.xlsx' ,content_books))\n",
        "\n",
        "#content_books=['/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/computos/20_oaxaca/oaxaca_casillas/oaxaca_municipios_2013_polling_place.xlsx'] #@param {type:\"string\"}\n",
        "\n",
        "sabana_dir = \"/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/respaldos/SabanaDatos_updated.xlsx\"\n",
        "column_find='IDEDO_IDSECC'\n",
        "\n",
        "#dir_content_books = \"/gdrive/My\\ Drive/PRI_CNIP_ESTRUCTURAS/computos/1_aguascalientes/aguascalientes_casillas/\"#@param {type:\"raw\"}\n",
        "#patron_list_files=\"*mun*2013*xlsx| tr '\\n' '\\n'\" #@param {type:\"raw\"}\n",
        "#content_books=!ls {dir_content_books+patron_list_files }\n",
        "\n",
        "\n",
        "def scan_column_zero(name_scan_column,df):\n",
        "  '''Return true if name_scan_column sum zero for a dataframe '''\n",
        "  sum=df[name_scan_column].sum()\n",
        "  if sum == 0:\n",
        "    print(f'La columna de {name_scan_column} suma cero')\n",
        "    return True\n",
        "  return False\n",
        "    \n",
        "def add_new_sheet(name_book,df,name_sheet):\n",
        "  ''' add new sheet, if the sheet exists it will be overwritten'''\n",
        "  book = load_workbook(name_book)\n",
        "  writer = pd.ExcelWriter(name_book, engine = 'openpyxl', mode='w')\n",
        "  writer.book = book\n",
        "  writer.sheets = dict((ws.title, ws) for ws in book.worksheets) \n",
        "  df.to_excel(writer, sheet_name = name_sheet, index=False)\n",
        "  writer.save()\n",
        "  writer.close()\n",
        "\n",
        "def mun_id(column_find,section_id, state_id,df_sabana):\n",
        "  ''' find mun id in column concat state+_+section_id if not found it return 0'''\n",
        "  keys = str(state_id) + '_' + str(section_id)\n",
        "  mun = list(df_sabana[df_sabana[column_find]==keys]['IDMPIO'].values)\n",
        "  if mun:\n",
        "    return mun[0]\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def sabana(column_origin, new_column, sheet, content_books, new_sheet, name_scan_column):\n",
        "  '''create a new sheet o replace with new columns with id's from sabana file '''\n",
        "  dicc_info={}\n",
        "  list_dicc_info=[]\n",
        "  muns_id=[]\n",
        "  zero_sections_muns=[]\n",
        "  df_sabana=pd.read_excel(sabana_dir)\n",
        "  preview_mun=False\n",
        "  for book in content_books:\n",
        "    state_origin=int(book.split(origin_computes)[1].split('_')[0])\n",
        "    #print(state_origin)\n",
        "    if state_origin == 16: # error in this files :(\n",
        "      continue\n",
        "    preview_mun=False\n",
        "\n",
        "    print(book)\n",
        "    try:\n",
        "      _df_origin = pd.read_excel(book, sheet_name=sheet)\n",
        "    except:\n",
        "      print('hey can\\'t read this file !')\n",
        "      continue\n",
        "    \n",
        "    if  not scan_column_zero(name_scan_column,_df_origin):\n",
        "      #print(f'La columna de {name_scan_column} ya tiene valores previos')\n",
        "      preview_mun=True\n",
        "\n",
        "    list_b = list(_df_origin[column_origin])\n",
        "    \n",
        "    for section in list_b:\n",
        "      _mun_id = mun_id(column_find=column_find, \n",
        "                       section_id=section, \n",
        "                       state_id=state_origin, \n",
        "                       df_sabana=df_sabana)\n",
        "      \n",
        "      muns_id.append(_mun_id)\n",
        "      if _mun_id == 0:\n",
        "        zero_sections_muns.append(section)\n",
        "\n",
        "    #_df_origin[new_column]=muns_id\n",
        "    _df_origin.insert(4, new_column,muns_id  )\n",
        "    comparation=list(map(lambda x,y: x==y, _df_origin[name_scan_column], _df_origin[new_column]))\n",
        "    _df_origin.insert(5, 'comparation',comparation)\n",
        "\n",
        "    #display(HTML(_df_origin.head(1).to_html()))\n",
        "\n",
        "    add_new_sheet(name_book=book,df=_df_origin,name_sheet=new_sheet)  \n",
        "    '''print('\\nSecciones que no tuvieron conversión a su id municipality y quedaron en ceros: ')\n",
        "    print(set(zero_sections_muns))\n",
        "    print('\\nSummary comparation')\n",
        "    print(set(comparation))\n",
        "    print('\\nPreview municipality')\n",
        "    print(preview_mun)'''\n",
        "\n",
        "\n",
        "    dicc_info[book]={'book': book,'preview_mun': preview_mun, 'zero_sections': set(zero_sections_muns), 'comparation': set(_df_origin['comparation'].values)}\n",
        "    list_dicc_info.append(dicc_info[book])\n",
        "    zero_sections_muns=[]\n",
        "    muns_id=[]\n",
        "  return list_dicc_info\n",
        "\n",
        "\n",
        "list_dicc_info=sabana(column_origin, new_column, sheet, content_books, new_sheet, name_scan_column)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_info=pd.DataFrame(list_dicc_info)\n",
        "display(HTML(df_info.to_html()))\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_EKf2Yqy2Jp",
        "colab_type": "text"
      },
      "source": [
        "# SECTION 3: ANALYZE EMPTY CELLS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfx-vGGAaTpE",
        "colab_type": "text"
      },
      "source": [
        "* No crea hojas nuevas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zc_r3kEcOLq",
        "colab_type": "text"
      },
      "source": [
        "Esta sección nos ayuda a identificar las columnas que tienen celdas con NaN(\"Not a Number\" para nuestro caso igual a:  \"vacías\"), así como el tipo de dato presente en cada columna.\n",
        "\n",
        "> * Recibe una lista con los nombres de las hojas que deseamos leer en cada libro.\n",
        "> * También recibe una cadena que representa un patrón, el cuál busca los archivos excel cargados.\n",
        "> * A veces solo nos interesa ver la info de las hojas que tienen celdas NaN, entonces hay que marcar la casilla filter_only_sheets_nan.\n",
        "> * Marca la casilla print_list_sheets si quieres ver el contenido de cada hoja procesada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgOgd05uO5WP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mi_lista=['20_oaxaca/oaxaca_casillas/oaxaca_municipios_2013_polling_place',\n",
        "          '7_chiapas/chiapas_casillas/chiapas_municipios_2018_polling_place']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StAfkacBQSqp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Summary NaN types\n",
        "\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "sheets =  ['Election','Polling_places']#@param {type:\"raw\"}\n",
        "filter_only_sheets_nan = False #@param {type:\"boolean\"}\n",
        "view_list_sheets = False #@param {type:\"boolean\"}\n",
        "\n",
        "#content_books =  \"*.xlsx | tr '\\n' '\\n'\"#@param {type:\"raw\"}\n",
        "#content_books=!ls {content_books}\n",
        "\n",
        "\n",
        "content_books=mi_lista  #@param {type:\"raw\"}\n",
        "origin_computes='/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/computos/'\n",
        "content_books=list(map(lambda x: origin_computes+x+'.xlsx' ,content_books))\n",
        "\n",
        "\n",
        "\n",
        "def count_nan_in_columns_by_sheet(content_books, sheets):\n",
        "  '''Return dicc with conteo_NaN info by sheet in content_books ''' \n",
        "  list_data=[]\n",
        "  dicc_data={}\n",
        "\n",
        "  for sheet in sheets:\n",
        "    for file_name in content_books:\n",
        "      try:\n",
        "        sheet_to_df = pd.read_excel(file_name, sheet_name=sheet)\n",
        "      except:\n",
        "        print(f'\\n ¡AVISO! No existe la hoja {sheet} en este archivo {file_name}')\n",
        "        continue\n",
        "\n",
        "      shape = sheet_to_df.shape\n",
        "      tipos=set(sheet_to_df.dtypes.values)\n",
        "      \n",
        "\n",
        "      df_types = pd.DataFrame([sheet_to_df.dtypes], columns=sheet_to_df.columns)\n",
        "\n",
        "      df_types = df_types.append(sheet_to_df, ignore_index=True)\n",
        "      df_types = df_types.rename(index = {0: 'data_column_type'})\n",
        "      \n",
        "      dicc_data = {'Archivo': file_name}\n",
        "      dicc_data.update({'Hoja': sheet})\n",
        "      dicc_data.update({'Contenido': str(shape[0]) + ' filas, '+ str(shape[1])+ ' columnas'})\n",
        "\n",
        "      if sheet_to_df.isnull().sum().sum() == 0:\n",
        "          msg = 'No tiene ninguna celda tipo NaN'\n",
        "          \n",
        "      else:\n",
        "          null_columns = sheet_to_df.columns[sheet_to_df.isnull().any()]\n",
        "          msg=''.join(sheet_to_df[null_columns].isnull().sum().to_string()).split('\\n')\n",
        "          msg=', '.join(msg)\n",
        "\n",
        "      if len(tipos)>1:\n",
        "            msg = msg + ', pero tiene más de un tipo de datos' + str(tipos)\n",
        "\n",
        "      dicc_data.update({'Aviso': msg })\n",
        "      list_data.append(dicc_data)\n",
        "\n",
        "      if view_list_sheets:\n",
        "\n",
        "          print('\\nArchivo:',file_name)\n",
        "          print('________                                                    ')\n",
        "          print('\\t| Hoja:',sheet, '\\t',shape[0], 'filas, ', shape[1], 'columnas')\n",
        "          print('\\t| Aviso conteo NaN:',msg,' |\\n')\n",
        "          if 'Polling_places' in sheet:\n",
        "            display(HTML(df_types.head(2).to_html()))\n",
        "          else:\n",
        "            display(HTML(df_types.to_html()))\n",
        "\n",
        "\n",
        "\n",
        "  return list_data\n",
        "\n",
        "\n",
        "list_data=count_nan_in_columns_by_sheet(content_books, sheets)\n",
        "\n",
        "df=pd.DataFrame([[fila['Archivo'], \n",
        "                  fila['Aviso'], \n",
        "                  fila['Contenido'], \n",
        "                  fila['Hoja']] \n",
        "                 for fila in list_data] , columns=['archivo', 'conteo_NaN', 'contenido', 'hoja'])\n",
        "\n",
        "if filter_only_sheets_nan:\n",
        "  df=df[~df.conteo_NaN.str.contains('No tiene')]\n",
        "\n",
        "print('\\nRESUMEN:\\n')\n",
        "display(HTML(df.to_html()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFbZYH_L_w3L",
        "colab_type": "text"
      },
      "source": [
        "# SECTION 4: CONVERSION TO INTEGERS\n",
        "######  \n",
        "* Si crea hojas nuevas\n",
        "\n",
        "> *   Modifica a integer los valores de las columnas\n",
        "*   De no ser posible la conversión, intenta reemplazar a 0's espacios en blanco y los que cumplan con un patrón regular.\n",
        "*   En el mismo archivo agrega una hoja nueva 'Polling_places_corrections'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "SukU-lgQ1V_b",
        "colab": {}
      },
      "source": [
        "#@title Definir funciones a usar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "def add_new_sheet_index(name_book,df,name_sheet):\n",
        "  ''' add new sheet, if the sheet exists new sheet with other index will be created'''\n",
        "  book = load_workbook(name_book)\n",
        "  writer = pd.ExcelWriter(name_book, engine = 'openpyxl', mode='w')\n",
        "  writer.book = book\n",
        "  df.to_excel(writer, sheet_name = name_sheet, index=False)\n",
        "  writer.save()\n",
        "  writer.close()\n",
        "\n",
        "def add_new_sheet(name_book,df,name_sheet):\n",
        "  ''' add new sheet, if the sheet exists it will be overwritten'''\n",
        "  book = load_workbook(name_book)\n",
        "  writer = pd.ExcelWriter(name_book, engine = 'openpyxl', mode='w')\n",
        "  writer.book = book\n",
        "  writer.sheets = dict((ws.title, ws) for ws in book.worksheets) \n",
        "  #print(writer.sheets) \n",
        "  df.to_excel(writer, sheet_name = name_sheet, index=False)\n",
        "  writer.save()\n",
        "  writer.close()\n",
        "\n",
        "def types_columns_unique(types_dataframe):\n",
        "  ''' generate a set of types columns from columns dataframe'''\n",
        "  return ','.join(map(str, set(list(types_dataframe))))\n",
        "\n",
        "\n",
        "def adjust_integers(content_books, sheet_name, new_sheet_name, regex_pattern_aditional=r'^-*$|^o+$|^O+$'):\n",
        "  ''' Try to convert all columns in a sheet_name to integer, \n",
        "      from each book in content_books '''\n",
        "  all_columns_integer={}\n",
        "  print(f'\\nSe creará NUEVA HOJA \"{new_sheet_name}\" para cada uno de los archivos siguientes, con los ajustes que se muestran en summary')\n",
        "  for book in content_books:\n",
        "    sustituir_vacios = True\n",
        "    original_all_numbers = False\n",
        "    print('\\n\\nLeyendo Libro:',book)\n",
        "    \n",
        "    try:\n",
        "      df_temp = pd.read_excel(book,sheet_name=sheet_name)\n",
        "    except:\n",
        "      print(f'\\tNo tiene la hoja: {sheet_name}')\n",
        "      continue\n",
        "\n",
        "    all_columns_integer[book]={}\n",
        "\n",
        "    try:\n",
        "      df_temp = df_temp.astype(int, errors='raise')\n",
        "      sustituir_vacios = False\n",
        "      original_all_numbers = True\n",
        "    except ValueError as e:\n",
        "      print('\\n\\tAVISO: Se encontraron valores que no se pueden convertir a entero directamente...')\n",
        "      #print('\\n\\t\\t!Info error 1:',e)\n",
        "      all_columns_integer[book]['integer'] = False\n",
        "    if sustituir_vacios:\n",
        "      try:\n",
        "        df_temp=df_temp.replace(r'^\\s*$', 0, regex=True).replace(regex_pattern_aditional, 0, regex=True)\n",
        "        #print(f'\\n\\tTRATAREMOS de SUSTITUIR valores VACÍOS, y los que cumplan este PATRÓN: {regex_pattern_aditional} por ceros')\n",
        "      except ValueError as e:\n",
        "        print('\\n\\tAVISO: Algún valor NO SE PUDO SUSTITUIR por 0\\'s \\:\\( ')\n",
        "        #print ('\\n\\t\\t!Info error 2:',e)\n",
        "    df_temp=df_temp.fillna(0)\n",
        "\n",
        "    try:\n",
        "      df_temp = df_temp.astype(int, errors='raise')\n",
        "      all_columns_integer[book]['integer'] = True\n",
        "    except ValueError as e:\n",
        "      print('\\n\\tAVISO: Existe algún valor que no se puede convertir a entero :S')\n",
        "      #print('\\n\\t\\t!Info error 3', e)\n",
        "      all_columns_integer[book]['integer'] = False\n",
        "    \n",
        "    all_columns_integer[book]['original_all_numbers'] = original_all_numbers\n",
        "    all_columns_integer[book]['types_unique'] = types_columns_unique(df_temp.dtypes)\n",
        "\n",
        "    g = dict(df_temp.columns.to_series().groupby(df_temp.dtypes).groups)   \n",
        "    types_columns={}\n",
        "\n",
        "    for k,v in g.items():\n",
        "      if not 'int' in (str(k)):\n",
        "        types_columns[str(k)]=','.join(list(v))\n",
        "\n",
        "    if not all_columns_integer[book]['integer']:\n",
        "      print('\\n\\tAVISO: Intenta un proceso individual para cada columna ...')\n",
        "    types_columns.update({'book':book.split('.')[0]})\n",
        "    all_columns_integer[book]['types_by_column'] = types_columns\n",
        "    add_new_sheet(name_book=book,df=df_temp,name_sheet=new_sheet_name)\n",
        "\n",
        "\n",
        "  print('\\nFin del proceso :)')\n",
        "  return all_columns_integer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVjt-_k-Rnah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mi_lista=['20_oaxaca/oaxaca_casillas/oaxaca_municipios_2013_polling_place',\n",
        "          '7_chiapas/chiapas_casillas/chiapas_municipios_2018_polling_place']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "UUGgOndU14D0",
        "colab": {}
      },
      "source": [
        "#@title Column to Integer Conversion Proccess\n",
        "\n",
        "content_books=mi_lista  #@param {type:\"raw\"}\n",
        "origin_computes='/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/computos/'\n",
        "content_books=list(map(lambda x: origin_computes+x+'.xlsx' ,content_books))\n",
        "\n",
        "all_columns_integer = adjust_integers(content_books = content_books, \n",
        "                                    sheet_name = 'Polling_places', \n",
        "                                    new_sheet_name = 'Polling_places_corrections',\n",
        "                                    regex_pattern_aditional = r'^-*$|^o+$|^O+$|^/+$')\n",
        "\n",
        "print('Summary_integers')\n",
        "df_sumary_integers = pd.DataFrame([[key.split('.')[0],value['integer'],value['original_all_numbers'], value['types_unique']] for key,value in all_columns_integer.items()], columns=['name_book', 'Finally Integer?','Began with numbers?', 'Types unique'])\n",
        "display(HTML(df_sumary_integers.to_html()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L-QSghRI6fOq"
      },
      "source": [
        "## SUBSECTION 2.1 Suggest changes in columns cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "hp8A0jRD6fOs",
        "colab": {}
      },
      "source": [
        "#@title Summary Columns cannot convert to Integers in a book\n",
        "df_columnas_not_int = pd.DataFrame([v['types_by_column'] for v in all_columns_integer.values() if not v['integer']])\n",
        "display(HTML(df_columnas_not_int.to_html()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "AEFoHZXA6fOv",
        "colab": {}
      },
      "source": [
        "#@title Proccess to suggest changes in columns\n",
        "def fix_multiple_types(n): \n",
        "    import re\n",
        "    tipo=str(type(n))\n",
        "    x=n\n",
        "    if 'int' in tipo:\n",
        "      return n\n",
        "    if 'str' in tipo:\n",
        "      numbers_patron = re.compile(r\"[\\d]\", re.X)\n",
        "      number=''.join(numbers_patron.findall(n))\n",
        "      try: \n",
        "        n=int(number)\n",
        "        print( '\\t\\t\\tAhora: ',str(type(n)), str(n), '\\tAntes:', tipo, str(x))\n",
        "        return n\n",
        "      except:\n",
        "        pass\n",
        "    elif 'float' in tipo:\n",
        "      if n >= 0:\n",
        "        n=int(n)\n",
        "        return n\n",
        "    print('\\t\\t\\tAhora:', str(type(0)),str(0), '\\tAntes:', str(type(x)), str(x))\n",
        "    return 0\n",
        "\n",
        "def fix_multiple_types_suggest_columns(n): \n",
        "    import re\n",
        "    tipo=str(type(n))\n",
        "    x=n\n",
        "    if 'int' in tipo:\n",
        "      return n\n",
        "    if 'str' in tipo:\n",
        "      numbers_patron = re.compile(r\"[\\d]\", re.X)\n",
        "      number=''.join(numbers_patron.findall(n))\n",
        "      try: \n",
        "        n=int(number)\n",
        "        n=''.join(['Ahora: ',str(type(n)),' ', str(n), ' Antes: ', tipo, str(x)])\n",
        "        return n\n",
        "      except:\n",
        "        pass\n",
        "    elif 'float' in tipo:\n",
        "      if n >= 0:\n",
        "        n=int(n)\n",
        "        return n\n",
        "    return ''.join(['Ahora: ', str(type(0)),' ', str(0), ' Antes: ', str(type(x)), str(x)])\n",
        "   \n",
        "\n",
        "for k,v in all_columns_integer.items():\n",
        "  df_temp_columns_suggest = pd.read_excel(k,sheet_name='Polling_places')\n",
        "  df_temp_sheet_suggest = pd.read_excel(k,sheet_name='Polling_places')\n",
        "\n",
        "  print('LIBRO:',k,'\\t')\n",
        " \n",
        "  if not v['integer']:\n",
        "    for key, tipos in v['types_by_column'].items():\n",
        "      if key == 'book':\n",
        "        continue\n",
        "      print('TIPO:',key)\n",
        "      \n",
        "      for c in tipos.split(','):\n",
        "        print('\\n\\tColumna:\\n\\t',c,'\\n')\n",
        "        df_temp_sheet_suggest[c]=list(map(fix_multiple_types,list(df_temp_sheet_suggest[c])))\n",
        "        #df_temp_columns_suggest[c+'suggested']= df_temp_columns_suggest[c].map(fix_multiple_types_suggest_columns)\n",
        "        df_temp_columns_suggest[c]= df_temp_columns_suggest[c].map(fix_multiple_types_suggest_columns)\n",
        "\n",
        "    df_temp_sheet_suggest.astype(int, errors='ignore')\n",
        "    df_temp_columns_suggest.astype(int, errors='ignore')\n",
        "    \n",
        "\n",
        "    add_new_sheet(name_book=k,df=df_temp_sheet_suggest,name_sheet='Polling_places_corrections')\n",
        "    add_new_sheet(name_book=k,df=df_temp_columns_suggest,name_sheet='Polling_places_suggested')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLetwF-Zq5z4",
        "colab_type": "text"
      },
      "source": [
        "# SECTION 5: ANALYZE 'Election'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vgxTZMRC51o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mi_lista=['20_oaxaca/oaxaca_casillas/oaxaca_municipios_2013_polling_place',\n",
        "          '7_chiapas/chiapas_casillas/chiapas_municipios_2018_polling_place']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZFvKeiCq5Et",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Comprobar hoja Election\n",
        "columnas_plantilla_election1=['State','Year','Election_type','Total_votes','Nominal_list','Computed_transactions','Fidelity']\n",
        "#columnas_plantilla_Polling_places=['section_id', 'local_disctrict_id', 'municipality_id', 'state_id','Not_reg','Null_votes']\n",
        "columnas_plantilla_election=set(['State','Year','Election_type','Total_votes','Nominal_list','Computed_transactions','Fidelity'])\n",
        "lista_elections=[]\n",
        "dicc_election={}\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "import pandas as pd\n",
        "\n",
        "#content_books =  \"*.xlsx | tr '\\n' '\\n'\"#@param {type:\"raw\"}\n",
        "#content_books =  !ls {content_books}\n",
        "\n",
        "\n",
        "content_books=mi_lista  #@param {type:\"raw\"}\n",
        "origin_computes='/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/computos/'\n",
        "content_books=list(map(lambda x: origin_computes+x+'.xlsx' ,content_books))\n",
        "\n",
        "\n",
        "for k in content_books:\n",
        "  dicc_election={}\n",
        "  print('|',k)\n",
        "  try:\n",
        "    xls = pd.ExcelFile(k)\n",
        "  except:\n",
        "    print('No es un archivo válido')\n",
        "    continue\n",
        "  if not 'Election' in xls.sheet_names:\n",
        "    print(f'\\n\\tNo existe la hoja Election para este archivo {k}')\n",
        "    continue\n",
        "  try:\n",
        "    data_election=pd.read_excel(k,sheet_name='Election')\n",
        "  except:\n",
        "    print(f'No se puede leer el archivo{k}')\n",
        "    continue\n",
        "  dicc_election['book']=k\n",
        "  columnas_hoja_election=set(data_election.columns)\n",
        "\n",
        "  if  not columnas_plantilla_election-columnas_hoja_election:\n",
        "    #print('\\tColumnas igual a la plantilla!\\n')\n",
        "    header_equal=True\n",
        "  else:\n",
        "    print('AVISO! Falta al menos una columna con respecto a la plantilla\\n')\n",
        "    header_equal=False\n",
        "\n",
        "  dicc_election['header_equal']=header_equal\n",
        "\n",
        "  dicc_election['types_column']=list(data_election.dtypes)\n",
        "  try:\n",
        "    dicc_election['values_fila']=list(data_election.iloc[0])\n",
        "  except:\n",
        "    dicc_election['values_fila']=list(['']*len(columnas_plantilla_election))\n",
        "    print('AVISO! Fila vacía')\n",
        "\n",
        "  lista_elections.append(dicc_election)\n",
        "  df_=pd.DataFrame([dicc_election['types_column'],dicc_election['values_fila'] ], index=['types','values'],columns=columnas_plantilla_election1)\n",
        "  print()\n",
        "  display(HTML(df_.to_html()))\n",
        "  print()\n",
        "\n",
        "df_2=pd.DataFrame(lista_elections)\n",
        "display(HTML(df_2.to_html()))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWpqbwXsAJ87",
        "colab_type": "text"
      },
      "source": [
        "# SECTION 6: EDITING COLUMN NAMES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ0KfIEHyey3",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Definir funciones a usar\n",
        "def reemplazar_nombres_columnas(df_temp, reemplazar):\n",
        "  '''Recibe un nuevo nombre de columna y lo reemplaza por una anteriormente dado'''\n",
        "  \n",
        "  if reemplazar == 'Y':\n",
        "\n",
        "    print(\"\\t¿Cuál es nombre de columna a reemplazar? \", end=\"\")\n",
        "    columna_anterior = input()\n",
        "    print(\"\\t¿Cuál es el nuevo nombre de columna?\", end=\"\")\n",
        "    columna_nueva = input()\n",
        "    print(f\"\\n\\tSe reemplazará: {columna_anterior} por {columna_nueva}\")\n",
        "\n",
        "    if columna_anterior in df_temp.columns and columna_nueva:\n",
        "  \n",
        "      df_temp.rename(columns={ columna_anterior :columna_nueva},inplace=True)\n",
        "      \n",
        "      print ('\\n\\tREEMPLAZO LISTO!\\n')\n",
        "      print('\\n\\tESTAS SON LAS COLUMNAS AHORA:\\n\\n\\t',df_temp.columns)\n",
        "    else:\n",
        "      print(f'{columna_anterior} No es una columna existente! y/o recuerda agregar el texto por el cual sustituir')\n",
        "\n",
        "  print('\\n\\t ¿Deseas reemplazar el nombre de otra columna? (Y/N)')\n",
        "  reemplazar = input()\n",
        "\n",
        "  if reemplazar == 'Y':\n",
        "    df_temp=reemplazar_nombres_columnas(df_temp, reemplazar)\n",
        "    print('\\tSe actualizará el nombre de la columna en el archivo de excel')\n",
        "  else:\n",
        "    print('\\tFinalizando edición de columnas de este archivo...')\n",
        "\n",
        "  return df_temp\n",
        "\n",
        "\n",
        "def rename_columns(content_books=[], sheet_name='Polling_places_corrections'):\n",
        "  '''Reads the name and renames certain columns of a sheet'''\n",
        "  for book in content_books:\n",
        "\n",
        "    print('\\n\\nNOMBRE DEL ARCHIVO:',book)\n",
        "    try:\n",
        "      df_temp=pd.read_excel(book,sheet_name=sheet_name)\n",
        "    except:\n",
        "      print(f'No existe la hoja {sheet_name} en el archivo: {book}')\n",
        "      continue\n",
        "    print('\\n\\n\\tESTAS SON LAS COLUMNAS PRESENTES:\\n\\n')\n",
        "    print('\\t',df_temp.columns)\n",
        "    print('\\n\\t¿Deseas reemplazar el nombre de alguna columna? (Y/N)')\n",
        "\n",
        "    reemplazar = input()\n",
        "\n",
        "    if reemplazar == 'Y': \n",
        "      df_temp = reemplazar_nombres_columnas(df_temp,reemplazar)\n",
        "      add_new_sheet(name_book=book,df=df_temp,name_sheet=sheet_name)\n",
        "      print('\\tSe actualizó el nombre de la columna en el archivo de excel')\n",
        "    else:\n",
        "      if reemplazar == 'N':\n",
        "        print('\\tBye!')\n",
        "      else:\n",
        "        print('\\tOpción no válida, pasaremos al siguiente archivo...')\n",
        "\n",
        "  return print('\\nProceso finalizado :D')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZLKqSShDu-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mi_lista=['20_oaxaca/oaxaca_casillas/oaxaca_municipios_2013_polling_place',\n",
        "          '7_chiapas/chiapas_casillas/chiapas_municipios_2018_polling_place']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riLM0ZDc1Snv",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Proccess to help us to rename columns\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "#content_books =  \"*.xlsx | tr '\\n' '\\n'\"#@param {type:\"raw\"}\n",
        "#content_books =  !ls {content_books}\n",
        "\n",
        "content_books=mi_lista  #@param {type:\"raw\"}\n",
        "origin_computes='/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/computos/'\n",
        "content_books=list(map(lambda x: origin_computes+x+'.xlsx' ,content_books))\n",
        "\n",
        "\n",
        "sheet_name=\"Polling_places_sabana_sergs\"#@param {type:\"string\"}\n",
        "\n",
        "\n",
        "rename_columns(content_books=content_books, sheet_name=sheet_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXXfbYXlu_p0",
        "colab_type": "text"
      },
      "source": [
        "# SECCIÓN 7:  Split Computations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ8czaw5af4a",
        "colab_type": "text"
      },
      "source": [
        "* Crea la hoja Polling_places_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF3UDYkHzMzp",
        "colab_type": "text"
      },
      "source": [
        "Esta sección nos ayuda a separar una columna apilada dada (C. Independiente n), en múltiples columnas agrupando por una columna pivote (municipality_id)\n",
        "\n",
        "> * Agregar el nombre de la hoja a leer,\n",
        "> * Agregar el nombre de la nueva hoja a crear\n",
        "> * Agregar el patrón de los archivos a leer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF0D4I1Ztgqi",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Functions [Split Computations]\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "\n",
        "def some_column_begin_with(columns, phrase='C. Independiente'):\n",
        "  for column in columns:\n",
        "    if phrase in column:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def filter_columns(columns, phrase='C. Independiente'):\n",
        "    return filter(lambda c: phrase in c, columns)\n",
        "\n",
        "def add_new_sheet(name_book,df,name_sheet):\n",
        "  ''' add new sheet, if the sheet exists it will be overwritten'''\n",
        "  book = load_workbook(name_book)\n",
        "  writer = pd.ExcelWriter(name_book, engine = 'openpyxl', mode='w')\n",
        "  writer.book = book\n",
        "  writer.sheets = dict((ws.title, ws) for ws in book.worksheets) \n",
        "  df.to_excel(writer, sheet_name = name_sheet, index=False)\n",
        "  writer.save()\n",
        "  writer.close()\n",
        "\n",
        "\n",
        "def split_column_in_columns(content_books,sheet, sort_column):\n",
        "  '''split a stacked column\n",
        "  (Independent C. n's), in multiple columns\n",
        "  by filter value of another column (municipality_id)'''\n",
        "\n",
        "  new_computes=[]\n",
        "  computes_mun=[]\n",
        "  phrase='C. Independiente' \n",
        "  pivot_column='municipality_id'\n",
        "  report_sheet_created={}\n",
        "  list_report_sheet_created=[]\n",
        "\n",
        "  for file_name in content_books:\n",
        "    new_computes=[]\n",
        "    try:\n",
        "      my_data = pd.read_excel(file_name, sheet_name=sheet)\n",
        "    except:\n",
        "      print(f'No existe Polling places en el archivo o no se puede acceder a él {file_name}')\n",
        "      continue\n",
        "    \n",
        "    my_data = my_data.sort_values(sort_column)\n",
        "\n",
        "    if some_column_begin_with(my_data.columns, phrase):\n",
        "      muns = my_data[pivot_column].unique()\n",
        "\n",
        "      #print(muns)\n",
        "      for mun in muns:\n",
        "        df_mun = my_data.loc[my_data[pivot_column] == mun].copy()\n",
        "\n",
        "        for n_independiente in filter_columns(my_data.columns, phrase):\n",
        "          if df_mun[n_independiente].sum() > 0:\n",
        "            df_mun[n_independiente +'_mun_'+str(mun)] = df_mun[n_independiente]\n",
        "            \n",
        "        computes_mun = df_mun.to_dict('records')\n",
        "        new_computes.extend(computes_mun)\n",
        "         \n",
        "      new_data = pd.DataFrame(new_computes)\n",
        "      new_data = new_data.fillna(0)\n",
        "      new_data = new_data.astype(int)\n",
        "\n",
        "      print(f'Se creó la hoja: {new_sheet} en el archivo:{file_name}')\n",
        "      add_new_sheet(file_name, new_data, new_sheet)\n",
        "      sheet_created=True\n",
        "      report_sheet_created={\n",
        "          'file_name': file_name,\n",
        "          'sheet_created': sheet_created,\n",
        "          'new_data_columns': new_data.columns.values,\n",
        "          'new_data_shape': new_data.shape}\n",
        "\n",
        "    else:\n",
        "      print(f'No existen C. Independientes en el archivo: {file_name},solo se ordenó por {sort_column}')\n",
        "      add_new_sheet(file_name, my_data, sheet)\n",
        "      sheet_created=False\n",
        "      report_sheet_created={\n",
        "          'file_name': file_name,\n",
        "          'sheet_created': sheet_created,\n",
        "          'new_data_columns': my_data.columns.values,\n",
        "          'new_data_shape': my_data.shape}\n",
        "    list_report_sheet_created.append(report_sheet_created)\n",
        "    computes_mun={}\n",
        "  return list_report_sheet_created\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yYihykIbS-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mi_lista=['8_chihuahua/8_chihuahua_casillas/chihuahua_municipios_2016_polling_place', \n",
        "          '20_oaxaca/oaxaca_casillas/oaxaca_municipios_2013_polling_place',\n",
        "          '7_chiapas/chiapas_casillas/chiapas_municipios_2018_polling_place']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l44EnhTIvNYM",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Split columns from computations\n",
        "\n",
        "sheet=\"Polling_places\"#@param {type:\"string\"}\n",
        "new_sheet=\"Polling_places_split\"#@param {type:\"string\"}\n",
        "sort_column=\"municipality_id\"#@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#content_books =  \"*.xlsx | tr '\\n' '\\n'\"#@param {type:\"raw\"}\n",
        "#content_books=!ls {content_books}\n",
        "\n",
        "\n",
        "content_books=mi_lista  #@param {type:\"raw\"}\n",
        "origin_computes='/gdrive/My Drive/PRI_CNIP_ESTRUCTURAS/computos/'\n",
        "content_books=list(map(lambda x: origin_computes+x+'.xlsx' ,content_books))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "list_report_sheet_created=split_column_in_columns(content_books,sheet, sort_column)\n",
        "\n",
        "\n",
        "df_split=pd.DataFrame([[fila['file_name'].split('.')[0], \n",
        "                  fila['sheet_created'], \n",
        "                  fila['new_data_shape'], \n",
        "                  fila['new_data_columns']] \n",
        "                 for fila in list_report_sheet_created] , columns=['archivo', 'hoja Nueva?', 'filas,columnas', 'name_columns'])\n",
        "\n",
        "\n",
        "print('\\nRESUMEN:\\n')\n",
        "display(HTML(df_split.to_html()))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}